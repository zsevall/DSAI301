{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zsevall/DSAI301/blob/main/Zeynep_Seval_fall2024_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# zeynep_seval_2024660042_FINAL EXAM"
      ],
      "metadata": {
        "id": "OSkRFLz-fOgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1**\n",
        "Web Search Engine"
      ],
      "metadata": {
        "id": "ezmhNU36tkmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1a**"
      ],
      "metadata": {
        "id": "qbDelA4mgMTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1> Finding Data\n",
        "\n",
        "The flow of execution is:\n",
        "*   Takes a seed URL crawlWeb(seed)\n",
        "*   Get the page content using getPage\n",
        "*   Find all links on that page using get_all_links (which uses get_next_target)\n",
        "*   Visits each linked page recursively and Adds new links to our to-crawl list using union"
      ],
      "metadata": {
        "id": "4oRdcM_1aez9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From Midterm results\n",
        "\n",
        "def getPage(url): # This function does the actual work of fetching web pages:\n",
        "  try:\n",
        "    import urllib.request\n",
        "    page = urllib.request.urlopen(url).read()\n",
        "    page = page.decode(\"utf-8\")\n",
        "    return page\n",
        "  except:\n",
        "    return \"\"  # If anything goes wrong, return empty string\n",
        "\n",
        "\n",
        "\n",
        "def get_next_target(page):   # This is our link finder. It looks through HTML in the given page to find the next page/link:\n",
        "  start_link = page.find('<a href=')        # Find the start of a link tag\n",
        "  if start_link == -1:                      # If no link found\n",
        "    return None, 0                          # We're done here\n",
        "  start_quote = page.find('\"', start_link)  # Find the first quote of the URL\n",
        "  end_quote = page.find('\"', start_quote+1) # Find the ending quote\n",
        "  url = page[start_quote + 1:end_quote]     # Extract the URL\n",
        "  return url, end_quote                     # Return URL\n",
        "  # we return here end_quote as well because we will do a trick in main function, cut the page from that point\n",
        "\n",
        "\n",
        "\n",
        "def get_all_links(page):  # This function uses get_next_target repeatedly to find all links on a page and adds them into a list called links:\n",
        "  links = []                        # Start with empty list\n",
        "  while True:\n",
        "    url, endpos = get_next_target(page)  # Find next link\n",
        "    if url:                              # If we found one\n",
        "      links.append(url)                  # Add it to our list\n",
        "      page = page[endpos:]              # Move to rest of page\n",
        "    else:\n",
        "      break                             # No more links? We're done\n",
        "  return links\n",
        "\n",
        "\n",
        "# Helper function union which helps us add new URLs to our to-crawl list without duplicates\n",
        "# it will be used in Crawlweb function later\n",
        "\n",
        "def union(list1,list2):\n",
        "  for scoop in list2:              # for each item in the list\n",
        "    if scoop not in list1:         # If we haven't seen it before\n",
        "      list1.append(scoop)          # add it into list\n",
        "  return list1"
      ],
      "metadata": {
        "id": "QpuC4DkAtj-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2> Building Index\n",
        "\n",
        "The flow of execution is:\n",
        "*  Cleans HTML content (get_clean_page)\n",
        "*  Builds a searchable index (add_to_index, add_page_to_index)"
      ],
      "metadata": {
        "id": "7PLbRXmlb8Tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From HW5 Answers\n",
        "\n",
        "def getclearpage(content): # The HTML cleaning function:\n",
        "    # Extract title\n",
        "    title = content[content.find(\"<title>\")+7:content.find(\"</title>\")]\n",
        "    # Extract body\n",
        "    body = content[content.find(\"<body>\")+6:content.find(\"</body>\")]\n",
        "\n",
        "    # Remove HTML tags from body\n",
        "    while body.find(\">\") != -1:  # While there are still HTML tags\n",
        "        start = body.find(\"<\")   # Find start of tag\n",
        "        end = body.find(\">\")     # Find end of tag\n",
        "        # Remove the tag by taking everything before \"<\" and after \">\"\n",
        "        body = body[:start] + body[end+1:]\n",
        "\n",
        "    # Return combined clean text\n",
        "    return title + body\n",
        "\n",
        "def add_to_index(index, keyword, url):\n",
        "  if keyword in index:\n",
        "    index[keyword].append(url)\n",
        "  else:\n",
        "    index[keyword] = [url]\n",
        "\n",
        "def addPageToIndex(index, url, content):\n",
        "  content = getclearpage(content)\n",
        "  words = content.split()\n",
        "  for word in words:\n",
        "    add_to_index(index, word, url)\n"
      ],
      "metadata": {
        "id": "22E3lFY1tjsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3> Ranking\n",
        "\n",
        "The flow of execution is:\n",
        "*  Generates a graph indicating the interconnections between web pages while crawling the web (crawlWeb)\n",
        "*   Defines the ranking (computeRanks)\n",
        "*  Provides search functionality (lookup)"
      ],
      "metadata": {
        "id": "4h58J4l5dOiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From Lecture Notes Modified crawlWeb function for Ranking\n",
        "# The graph shows the structure of the web pages and their connections.\n",
        "# Each key in the graph is a web page (URL), and its value is a list of outlinks (other pages it links to).\n",
        "# This structure is used to model the relationships between pages, which can be analyzed for ranking and crawling.\n",
        "\n",
        "def crawlWeb(seed):\n",
        "    tocrawl = [seed]\n",
        "    crawled = []\n",
        "    index = {}\n",
        "    graph = {}  # Added to Initialize the graph dictionary for printing purpose in 1b\n",
        "\n",
        "    while tocrawl:\n",
        "        page = tocrawl.pop()\n",
        "        if page not in crawled:\n",
        "            content = getPage(page)\n",
        "            outlinks = get_all_links(content)  # Added to Get all outbound links\n",
        "            graph[page] = outlinks             # Adds the page and its outlinks to the graph\n",
        "            addPageToIndex(index, page, content)\n",
        "            union(tocrawl, outlinks)\n",
        "            crawled.append(page)\n",
        "\n",
        "    return index, graph  # Return both index and graph"
      ],
      "metadata": {
        "id": "l6yv-chdDVZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1b**"
      ],
      "metadata": {
        "id": "T3QOl-zvgqdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printGraph(graph): # print everything in required format\n",
        "    print(\"The graph has\", len(graph), \"elements:\")\n",
        "    count = 1\n",
        "    for page, outlinks in graph.items():\n",
        "        print(f\"\\t{count}. [{page}]: {outlinks}\")\n",
        "        count += 1\n",
        "\n",
        "# Execution\n",
        "seed_url = \"https://searchengineplaces.com.tr/\"\n",
        "index, graph = crawlWeb(seed_url)\n",
        "printGraph(graph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNtQH7-PlWSb",
        "outputId": "05a473e3-ef5a-4f3a-9ffd-c06a1fba2217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The graph has 10 elements:\n",
            "\t1. [https://searchengineplaces.com.tr/]: ['http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "\t2. [http://www.searchengineplaces.com.tr/travel_guide.html]: ['http://www.searchengineplaces.com.tr/ankara.html', 'http://www.searchengineplaces.com.tr/konya.html', 'http://www.searchengineplaces.com.tr/istanbul.html', 'http://www.searchengineplaces.com.tr/oktayrecommends.html', 'http://www.searchengineplaces.com.tr/seymarecommends.html']\n",
            "\t3. [http://www.searchengineplaces.com.tr/seymarecommends.html]: ['http://www.searchengineplaces.com.tr/oktayrecommends.html', 'http://www.searchengineplaces.com.tr/konya.html']\n",
            "\t4. [http://www.searchengineplaces.com.tr/oktayrecommends.html]: ['http://www.searchengineplaces.com.tr/istanbul.html']\n",
            "\t5. [http://www.searchengineplaces.com.tr/istanbul.html]: ['http://www.searchengineplaces.com.tr/maidens_tower.html', 'http://www.searchengineplaces.com.tr/galata_tower.html']\n",
            "\t6. [http://www.searchengineplaces.com.tr/galata_tower.html]: ['http://www.searchengineplaces.com.tr/istanbul.html', 'http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "\t7. [http://www.searchengineplaces.com.tr/maidens_tower.html]: ['http://www.searchengineplaces.com.tr/istanbul.html', 'http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "\t8. [http://www.searchengineplaces.com.tr/konya.html]: ['http://www.searchengineplaces.com.tr/seymarecommends.html', 'http://www.searchengineplaces.com.tr/mevlana.html']\n",
            "\t9. [http://www.searchengineplaces.com.tr/mevlana.html]: ['http://www.searchengineplaces.com.tr/travel_guide.html']\n",
            "\t10. [http://www.searchengineplaces.com.tr/ankara.html]: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1c**"
      ],
      "metadata": {
        "id": "vsrEM1d3gxQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From Lecture Notes\n",
        "def computeRanks(graph): # This function takes a graph dictionary as input where keys are pages and values are lists of outlinks:\n",
        "\n",
        "    d = 0.8                               # Dampening factor (probability of following a link vs. random jump)\n",
        "    N = len(graph)                        # Total number of pages in the graph\n",
        "    numloops = 10                         # Number of iterations to run the algorithm (more loops = more accurate)\n",
        "    ranks = {}                            # Initialize empty dictionary to store page ranks\n",
        "\n",
        "    for page in graph:                    # Initial setup: give each page an equal rank\n",
        "        ranks[page] = 1/N                 # Each page starts with rank 1/N (equal distribution)\n",
        "\n",
        "    for i in range(0, numloops):          # Main iteration loop to refine ranks\n",
        "        newranks = {}                     # Initialize empty dictionary for new rank values\n",
        "\n",
        "        for page in graph:                # For each page in the graph\n",
        "            newrank = (1-d)/N             # Start with the random probability\n",
        "\n",
        "            for node in graph:            # Find pages that link to this page\n",
        "                if page in graph[node]:   # If this node links to our page\n",
        "\n",
        "\n",
        "                    newrank = newrank + d*(ranks[node]/len(graph[node]))  # Add rank contribution from this inbound link:\n",
        "                                                                          # (node's rank * dampening factor) / (number of outbound links from node)\n",
        "            newranks[page] = newrank      # Store the calculated new rank for this page\n",
        "\n",
        "        ranks = newranks                  # Update the ranks dictionary with new values\n",
        "\n",
        "    return newranks                       # Return the final computed ranks\n"
      ],
      "metadata": {
        "id": "0VYCQKunenGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks = computeRanks(graph) # Compute ranks using the function"
      ],
      "metadata": {
        "id": "Cc4njCW4xxDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def printRanks(ranks): # helper To print everything in required format\n",
        "    for page, rank in ranks.items():\n",
        "        print(f\"The rank of the page {page} : {rank:.2f}\")  # Print rank with 2 decimal places for clarity\n",
        "\n",
        "# Execution\n",
        "printRanks(ranks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unl_hCRemRN-",
        "outputId": "7725410f-fc18-4a57-da6b-4e760a922d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rank of the page https://searchengineplaces.com.tr/ : 0.02\n",
            "The rank of the page http://www.searchengineplaces.com.tr/travel_guide.html : 0.15\n",
            "The rank of the page http://www.searchengineplaces.com.tr/seymarecommends.html : 0.07\n",
            "The rank of the page http://www.searchengineplaces.com.tr/oktayrecommends.html : 0.07\n",
            "The rank of the page http://www.searchengineplaces.com.tr/istanbul.html : 0.17\n",
            "The rank of the page http://www.searchengineplaces.com.tr/galata_tower.html : 0.09\n",
            "The rank of the page http://www.searchengineplaces.com.tr/maidens_tower.html : 0.09\n",
            "The rank of the page http://www.searchengineplaces.com.tr/konya.html : 0.07\n",
            "The rank of the page http://www.searchengineplaces.com.tr/mevlana.html : 0.05\n",
            "The rank of the page http://www.searchengineplaces.com.tr/ankara.html : 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1d**"
      ],
      "metadata": {
        "id": "ocGwesJGf6Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rankedLookup(index, key, graph):\n",
        "    if key not in index:\n",
        "        return []\n",
        "\n",
        "    # Calculate ranks\n",
        "    ranks = computeRanks(graph)\n",
        "\n",
        "    # remove duplicates\n",
        "    urls = index[key]\n",
        "    unique_urls = []\n",
        "    for url in urls:\n",
        "        # Only add URL if we haven't added already\n",
        "        if url not in unique_urls:\n",
        "            unique_urls.append(url)\n",
        "\n",
        "    # Sort unique URLs by their rank\n",
        "    sorted_urls = sorted(unique_urls, key=lambda x: ranks[x], reverse=True) # ALLOWED BUILT-IN FUNCTION\n",
        "    return sorted_urls"
      ],
      "metadata": {
        "id": "KlDhgbSIeyW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test rankedLookup\n",
        "index, graph = crawlWeb(seed_url)\n",
        "results = rankedLookup(index, \"in\", graph)\n",
        "for result in results:\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spgw0MSjfFxI",
        "outputId": "48f9d12d-0a50-4c37-9eb0-db4f7ce8777a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1e**\n",
        "\n",
        "Modify the original lookup function\n",
        "to optionally perform page ranking. This modification will be as follows:\n",
        "If the procedure is given 2 inputs, specifically an index and a key, it will function like\n",
        "the original lookup. However, if itâ€™s given 4 inputs, namely index, key, graph, and\n",
        "computing procedure, it will perform page ranking using the provided graph and computing procedure. In case of 3 inputs, it will raise a warning (not an error!) as specified\n",
        "below.\n",
        "\n",
        "\n",
        "Notice that both lookup with ranking option and rankedLookup do not provide the same\n",
        "URL multiple times in their outputs, as they are designed to rank URLs, resulting in each URL\n",
        "appearing only once. Make sure whatever parameter you use while calling the procedure, each\n",
        "url should be diplayed only once"
      ],
      "metadata": {
        "id": "gC3hr6ELhGcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup(index, key, graph=None, computing_procedure=None):\n",
        "    # an output string to collect results so that only one print is used\n",
        "    output = \"\"\n",
        "\n",
        "    # Check if the key exists in the index\n",
        "    if key not in index:\n",
        "        output += f\"No results found for key: {key}\\n\"\n",
        "    else:\n",
        "\n",
        "        # remove duplicates\n",
        "        urls = index[key]\n",
        "        unique_urls = []\n",
        "        for url in urls:\n",
        "            # Only add URL if we haven't added already\n",
        "            if url not in unique_urls:\n",
        "               unique_urls.append(url)\n",
        "\n",
        "        # standard lookup\n",
        "        if graph is None:\n",
        "            for url in unique_urls:\n",
        "                output += url + \"\\n\"\n",
        "\n",
        "        # lookup with ranking, SAME AS RANKED LOOKUP\n",
        "        elif computing_procedure:\n",
        "            ranks = computing_procedure(graph)\n",
        "            sorted_urls = sorted(unique_urls, key=lambda x: ranks[x], reverse=True)  # ALLOWED BUILT-IN FUNCTION\n",
        "            for url in sorted_urls:\n",
        "                output += url + \"\\n\"\n",
        "\n",
        "        # lookup with warning\n",
        "        else:\n",
        "            output += \"Warning: No ranking procedure given\\n\"\n",
        "            for url in unique_urls:\n",
        "                output += url + \"\\n\"\n",
        "\n",
        "    # Print all collected outputs at once\n",
        "    print(output)  # Single print statement\n"
      ],
      "metadata": {
        "id": "GSLX-hyShI4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "lookup(index, \"in\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A17nQoqUuzj",
        "outputId": "3842727f-0945-4590-e5b8-55ffe3817fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "lookup(index, \"in\", graph)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m9EJmmLlv-i",
        "outputId": "756febbc-e8ec-4f24-e24f-862b8d179641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: No ranking procedure given\n",
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "lookup(index, \"in\", graph, computing_procedure=computeRanks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVDFnZw2lzZG",
        "outputId": "b11a19e6-224f-4aea-ac43-7c903906b83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "http://www.searchengineplaces.com.tr/istanbul.html\n",
            "http://www.searchengineplaces.com.tr/travel_guide.html\n",
            "http://www.searchengineplaces.com.tr/galata_tower.html\n",
            "http://www.searchengineplaces.com.tr/maidens_tower.html\n",
            "http://www.searchengineplaces.com.tr/konya.html\n",
            "http://www.searchengineplaces.com.tr/mevlana.html\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2 - Wordle Game Solver**\n",
        "\n",
        "As you know, in the midterm exam, a problem involving playing the Wordle game using Python was presented. In this question, you will deal with a similar problem within the same concept.\n",
        "Your goal now is to make the *computer* play the Wordle game and correctly guess the word in the shortest number of attempts.\n",
        "As in the midterm, we have modularized the problem for you and provided a prepared template. By completing this template, you will solve the problem.\n",
        "\n",
        "You cannot make any changes to this file.\n",
        "To solve this question, you can either copy the code from each cell and paste it into your own notebook or save a copy in your Drive and work directly on that copy.\n",
        "\n",
        "You can access the answer key for the midterm Wordle question from the link below.\n",
        "\n",
        "https://colab.research.google.com/drive/12z3Bk4CSW4GWCpxX0WiftyzSdb3gTubp?usp=sharing\n",
        "\n",
        "\n",
        "In this problem, the main function we will run will be the `optimize_wordle()` function, and the `Wordle()` function you wrote will now be used as a helper function.  \n",
        "You need to completely change the structure of the Wordle function; it no longer needs to provide any colored output.  \n",
        "\n",
        "For the best optimization, the Wordle function should return three pieces of information for the input we provide:  \n",
        "- **list1**: Letters in the correct position.    \n",
        "- **list2**: Letters in the wrong position.  \n",
        "- **list3**: Letters not present in the word.  \n",
        "\n",
        "Hint: You can return these three pieces of information as three separate lists.  \n",
        "(For easier coding, you can structure these lists in different ways. (Nested lists might be useful.)\n",
        "\n",
        "\n",
        "In the provided templates, we add the `pass` statement at the end of functions to avoid errors when the cell is executed since the functions will be completed later. After writing the templates, you need to remove the `pass` statement.\n",
        "\n",
        "Additionally, in the provided templates, you will decide what inputs the functions should have. We will not include anything in these sections within the templates.\n"
      ],
      "metadata": {
        "id": "SjVRdFxKx68p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##IMPORTS\n",
        "Here we will import some libraries into the notebook and write functions for generating random words.\n"
      ],
      "metadata": {
        "id": "HH1PCm-E3jSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import random"
      ],
      "metadata": {
        "id": "8-GzY67NziDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ready Helper Functions\n",
        "\n",
        "We give you ready functions to return all English words as a list.\n",
        "\n",
        "If you do not understand the logic of these functions, this is not a problem, you just need to run the functions to solve the problem.\n",
        "\n",
        "##WARNING:\n",
        " If you are running Jupyter Notebook in a local environment like Anaconda, you may get an error because you did not download the library files to your computer, in this case it is your responsibility to solve this problem. We recommend using Google Colab, the functions will work without errors in Google Colab.\n",
        "\n",
        "##WARNING:\n",
        "Do not change the functions or links here, it may cause you to get an error.\n",
        "\n",
        "##WARNING:\n",
        "Please run these cells while your computer is connected to the internet because it needs to download all the English words from an external source."
      ],
      "metadata": {
        "id": "VkrRXpqV3xhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file_from_drive(file_url, colab_path):\n",
        "    if \"drive.google.com\" in file_url:\n",
        "        file_id = file_url.split('/d/')[1].split('/')[0]\n",
        "        download_url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "    else:\n",
        "        raise ValueError(\"The provided URL is not a valid Google Drive link.\")\n",
        "\n",
        "    response = requests.get(download_url, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(colab_path, 'wb') as file:\n",
        "            for chunk in response.iter_content(chunk_size=1024):\n",
        "                if chunk:\n",
        "                    file.write(chunk)\n",
        "        print(f\"File successfully downloaded to {colab_path}\")\n",
        "    else:\n",
        "        raise Exception(\"Failed to download the file. Check the URL or file permissions.\")\n",
        "\n",
        "colab_path = \"/content/words.txt\"\n",
        "file_url = \"https://drive.google.com/file/d/1cjCZ-5uAHVFLXLV6HuSM98_QblWaXrBZ/view?usp=share_link\"\n",
        "download_file_from_drive(file_url,colab_path)\n",
        "\n",
        "\n",
        "WORDLIST_FILENAME = \"words.txt\"\n",
        "\n",
        "def load_words():\n",
        "\n",
        "  inFile = open(WORDLIST_FILENAME, 'r')\n",
        "  line = inFile.readline()\n",
        "  wordlist = line.split()\n",
        "  print(\"  \", len(wordlist), \"words loaded.\")\n",
        "  return wordlist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laT4qAiN3txi",
        "outputId": "e750cf1b-0bb5-452c-9ab9-aef9e98734b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File successfully downloaded to /content/words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Function Templates\n",
        "\n",
        "In this question, the `wordle()` function compares the secretword and the guess, returning three lists ***(you may adjust the number of outputs if needed)***.  \n",
        "To avoid complexity and for simplicity in naming, use the following names for these three lists throughout the assignment:  \n",
        "\n",
        "- **list1**: Letters in the correct position.    \n",
        "- **list2**: Letters in the wrong position.  \n",
        "- **list3**: Letters not present in the word.\n",
        "\n",
        "You need to ensure that the computer makes guesses that are the same length as the `secretword`.\n",
        "\n",
        "\n",
        " #### HINTS FOR THE HELPER FUNCTIONS\n",
        "\n",
        " `word_select()`: We had provided this function to you as ready-made in the midterm, but for this question, you need to make a small modification to its structure. Additionally, you will later use this function to generate a random guess.\n",
        "\n",
        " `cleanwordlist()`: In this function, you can update your word list to ensure that the computer makes guesses with the same length as the secretword.  \n",
        "\n",
        "`updatelist1/2/3()`: If needed, you can use these three functions to update the lists that will be returned by the `wordle()` function.  \n",
        "\n",
        "Of course, you can solve the problem without these functions, but modularizing the problem makes things easier.  \n",
        "\n",
        "You can also define additional helper functions if you wish.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ME0HTIW74VAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_select(wordlist):\n",
        "    return random.choice(wordlist)"
      ],
      "metadata": {
        "id": "sHOVARhj3KqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updatelist1(guess, secretWord):\n",
        "    matches = []  # Correct letters in correct positions\n",
        "    i = 0         # Initialize index\n",
        "    while i < len(secretWord):\n",
        "        if guess[i] == secretWord[i]:  # if the letters match\n",
        "            matches.append([guess[i], i])  # Save the letter and its position\n",
        "        i += 1  # Move to the next index\n",
        "    return matches"
      ],
      "metadata": {
        "id": "-V--SlMIVYKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updatelist2(guess, secretWord, list1):\n",
        "    wrong_positions = []  # letters in wrong position\n",
        "    used_spots = []      # spots we already used\n",
        "\n",
        "    # Remember used spots from list1\n",
        "    i = 0\n",
        "    while i < len(list1):\n",
        "        used_spots.append(list1[i][1])\n",
        "        i += 1\n",
        "\n",
        "    # Look at each letter in our guess\n",
        "    i = 0\n",
        "    while i < len(guess):\n",
        "        # Skip if we already used this spot\n",
        "        if i not in used_spots:\n",
        "            letter = guess[i]\n",
        "            # Look for this letter in secret word\n",
        "            j = 0\n",
        "            while j < len(secretWord):\n",
        "                # If we find the letter and spot isn't used\n",
        "                if letter == secretWord[j] and j not in used_spots:\n",
        "                    # Remember letter and its wrong spot\n",
        "                    wrong_positions.append([letter, i])\n",
        "                    used_spots.append(j)\n",
        "                    break\n",
        "                j += 1\n",
        "        i += 1\n",
        "\n",
        "    return wrong_positions"
      ],
      "metadata": {
        "id": "zWmOe805VWBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def updatelist3(guess, secretWord, list1, list2):\n",
        "    wrong_letters = []   # letters not in word\n",
        "    right_letters = []   # letters we got right\n",
        "\n",
        "    # Remember letters we got right\n",
        "    i = 0\n",
        "    while i < len(list1):\n",
        "        right_letters.append(list1[i][0])\n",
        "        i += 1\n",
        "\n",
        "    i = 0\n",
        "    while i < len(list2):\n",
        "        right_letters.append(list2[i][0])\n",
        "        i += 1\n",
        "\n",
        "    # Check each letter in guess\n",
        "    i = 0\n",
        "    while i < len(guess):\n",
        "        letter = guess[i]\n",
        "        # If letter isn't in secret word and we haven't found it yet\n",
        "        if letter not in secretWord and letter not in wrong_letters:\n",
        "            wrong_letters.append(letter)\n",
        "        # If letter is in word but we found too many of it\n",
        "        elif letter not in right_letters and letter not in wrong_letters:\n",
        "            wrong_letters.append(letter)\n",
        "        i += 1\n",
        "\n",
        "    return wrong_letters"
      ],
      "metadata": {
        "id": "0hmbrgS-VfSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanwordlist(wordlist, secretWord):\n",
        "    # Make a new empty list for words with same length\n",
        "    cleaned_list = []\n",
        "    for word in wordlist:\n",
        "        if len(word) == len(secretWord):\n",
        "            cleaned_list.append(word)\n",
        "    return cleaned_list"
      ],
      "metadata": {
        "id": "rtUWAjEyboXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `wordle()` Procedure\n",
        "\n",
        "As explained above, the `wordle` function will now return three lists to provide information to the computer. Therefore, you need to completely change the structure of the function.  \n",
        "\n",
        "**Extra Hint:** Do not define a `secretword` within the `wordle` function. Instead, compare a pre-determined `secretword` and `guess` within this function.  \n"
      ],
      "metadata": {
        "id": "v1fsQTXE__qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wordle(guess,secretWord):\n",
        "  \"\"\"\n",
        "  Compare a guess with secretWord and return three lists:\n",
        "    - list1: Correct letters in correct positions\n",
        "    - list2: Correct letters in wrong positions\n",
        "    - list3: Letters not in word\n",
        "  \"\"\"\n",
        "  # Get feedback about the guess using our helper functions\n",
        "  list1 = updatelist1(guess, secretWord)\n",
        "  list2 = updatelist2(guess, secretWord, list1)\n",
        "  list3 = updatelist3(guess, secretWord, list1, list2)\n",
        "\n",
        "  return list1, list2, list3"
      ],
      "metadata": {
        "id": "eFwj1-2YAH53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `generate_guess()` Procedure\n",
        "\n",
        "This function will generate a new guess based on the information provided by the wordle function.\n",
        "\n",
        "For example, the information obtained from the previous guess includes:\n",
        "\n",
        "- **list1**: Letters in the correct position.    \n",
        "- **list2**: Letters in the wrong position.  \n",
        "- **list3**: Letters not present in the word.\n",
        "\n",
        "Using these lists, the function should refine its guesses and generate the next word accordingly.\n",
        "\n",
        "\n",
        "That means if we have the information that the word contains the letter `'e'` but not in the 3rd position, this function must select a word that includes the letter `'e'` and ensures that `'e'` is not in the 3rd position.  \n",
        "\n",
        "In this way, the function must choose a new word that adheres to all the information gathered so far.  \n",
        "\n",
        "Additionally, the new guess must also comply with all the information obtained from previous guesses. The function should consistently refine its guesses based on accumulated knowledge and eliminate invalid options from the pool of possible words."
      ],
      "metadata": {
        "id": "0IcE3UsUBFVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_guess(wordlist, list1, list2, list3, secretWord):\n",
        "    possible_words = cleanwordlist(wordlist, secretWord)  # list of words with matching length\n",
        "    newguess_words = []  # words that pass our checks\n",
        "\n",
        "    # Check each possible word\n",
        "    for word in possible_words:\n",
        "        # Assume word is good until we prove it's not\n",
        "        keeptheword = True\n",
        "\n",
        "        # Check list1 (right letters, right spots)\n",
        "        for item in list1:\n",
        "            letter = item[0]    # Get the letter\n",
        "            position = item[1]  # Get its position\n",
        "            if word[position] != letter:\n",
        "                keeptheword = False\n",
        "                break\n",
        "\n",
        "        # If word failed list1 check, try next word\n",
        "        if not keeptheword:\n",
        "            continue\n",
        "\n",
        "        # Check list2 (right letters, wrong spots)\n",
        "        for item in list2:\n",
        "            letter = item[0]           # Get the letter\n",
        "            wrong_position = item[1]   # Get position where it shouldn't be\n",
        "            if letter not in word or word[wrong_position] == letter:\n",
        "                keeptheword = False\n",
        "                break\n",
        "\n",
        "        # If word failed list2 check, try next word\n",
        "        if not keeptheword:\n",
        "            continue\n",
        "\n",
        "        # Check list3 (wrong letters)\n",
        "        for wrong_letter in list3:\n",
        "            if wrong_letter in word:  # If this wrong letter appears in word\n",
        "                keeptheword = False\n",
        "                break\n",
        "\n",
        "        # If word passed all checks, add it to newguess_words list\n",
        "        if keeptheword:\n",
        "            newguess_words.append(word)\n",
        "\n",
        "    # Return a random newguess_word if we found any\n",
        "    if newguess_words:\n",
        "        return word_select(newguess_words)\n",
        "    return None"
      ],
      "metadata": {
        "id": "dkFdqZ88BJkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `optimize_wordle()` Procedure\n",
        "\n",
        "The `optimize_wordle()` function is our main function, and it will be used to make the computer play the Wordle game. This is the function we will call to run the entire process.\n",
        "\n",
        "#### HINTS\n",
        "\n",
        "Set the target word as `secretword`.  \n",
        "Ensure that the computer generates guesses of the same length as the `secretword`.  \n",
        "Then, use a loop to sequentially generate a guess and send it to the `wordle` function. Continue this loop until the computer correctly guesses the word.  \n",
        "\n",
        "Once the computer has guessed the word, print the number of attempts it took and the list of words it guessed.  \n",
        "To make the function output more user-friendly, also display the computer's current guess in real time while the function is running.  \n"
      ],
      "metadata": {
        "id": "7E_7MFoWC-no"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Output\n",
        "    optimize_wordle()\n",
        "\n",
        "\\>>\n",
        "\n",
        "      55900 words loaded.\n",
        "\n",
        "    Secretword is :gong\n",
        "\n",
        "    Computer will try to find this word...\n",
        "\n",
        "    Computer's guess is: bite\n",
        "\n",
        "    Computer's guess is: arms\n",
        "\n",
        "    Computer's guess is: loop\n",
        "\n",
        "    Computer's guess is: jock\n",
        "\n",
        "    Computer's guess is: hong\n",
        "\n",
        "    Computer's guess is: gong\n",
        "\n",
        "    The computer guessed the word in 6 attempts.\n",
        "\n",
        "    List of the computer's guesses:['bite', 'arms', 'loop', 'jock', 'hong', 'gong']"
      ],
      "metadata": {
        "id": "3hWijlJvHJbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_wordle():\n",
        "    # Load words and pick secret word\n",
        "    wordlist = load_words()\n",
        "    secretWord = word_select(wordlist)\n",
        "\n",
        "    print(\"\\nSecretword is:\", secretWord)\n",
        "    print(\"\\nComputer will try to find this word...\")\n",
        "\n",
        "    # To Keep track of guesses\n",
        "    attempts = 0\n",
        "    guessed_words = []\n",
        "\n",
        "    # Store what we learn from each guess\n",
        "    correct = []     # right letter, right spot / use of list1\n",
        "    misplaced = []   # right letter, wrong spot / use of list2\n",
        "    wrong = []       # wrong letters / use of list3\n",
        "\n",
        "    while True:\n",
        "        # For first guess, just pick any random word with same length\n",
        "        if attempts == 0:\n",
        "            guess = word_select(cleanwordlist(wordlist, secretWord))\n",
        "        # For later guesses, use what we learned so far\n",
        "        else:\n",
        "            guess = generate_guess(wordlist, correct, misplaced, wrong, secretWord)\n",
        "\n",
        "        attempts += 1\n",
        "        guessed_words.append(guess)\n",
        "\n",
        "        print(\"\\nComputer's guess is:\", guess)\n",
        "\n",
        "        # If we found the word, we're done\n",
        "        if guess == secretWord:\n",
        "            print(\"\\nThe computer guessed the word in\", attempts, \"attempts.\")\n",
        "            print(\"List of computer's guesses:\", guessed_words)\n",
        "            return attempts\n",
        "\n",
        "        else:\n",
        "            # Get feedback about our guess\n",
        "            correct, misplaced, wrong = wordle(guess, secretWord)\n",
        "\n",
        "# Run Main Function\n",
        "optimize_wordle()"
      ],
      "metadata": {
        "id": "YvPuc-4aCxfz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91960e7-68ec-4f2f-e7e9-1a2b3266f66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   55900 words loaded.\n",
            "\n",
            "Secretword is: circumvent\n",
            "\n",
            "Computer will try to find this word...\n",
            "\n",
            "Computer's guess is: fallacious\n",
            "\n",
            "Computer's guess is: reinducted\n",
            "\n",
            "Computer's guess is: assurances\n",
            "\n",
            "Computer's guess is: uncommonly\n",
            "\n",
            "Computer's guess is: circumvent\n",
            "\n",
            "The computer guessed the word in 5 attempts.\n",
            "List of computer's guesses: ['fallacious', 'reinducted', 'assurances', 'uncommonly', 'circumvent']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mwnoTT1R8BDZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}